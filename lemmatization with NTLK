import nltk

# Download NLTK's WordNet corpus and 'averaged_perceptron_tagger' (if not already downloaded)
nltk.download('wordnet')
nltk.download('averaged_perceptron_tagger')

from nltk.stem import WordNetLemmatizer
from nltk.corpus import wordnet

lemmatizer = WordNetLemmatizer()

# Sample text (replace with your own text)
text = "The striped bats are hanging on their feet for best"

# Tokenize the text into words
words = nltk.word_tokenize(text)

# Lemmatize each word
lemmatized_words = []
for word in words:
    # Get the part-of-speech (POS) tag for the word
    pos_tag = nltk.pos_tag([word])[0][1][0].lower()  
    tag = wordnet.NOUN  # Default to noun if POS tag is not found in the mapping
    if pos_tag in ['j', 'a', 'v', 'r']:  # Map POS tags to WordNet tags
        tag = {'j': wordnet.ADJ, 'a': wordnet.ADJ_SAT, 'v': wordnet.VERB, 'r': wordnet.ADV}[pos_tag]
    lemma = lemmatizer.lemmatize(word, tag)  # Lemmatize with POS tag
    lemmatized_words.append(lemma)

print("Original Text:", text)
print("Lemmatized Text:", " ".join(lemmatized_words))  # Reconstruct the lemmatized text
